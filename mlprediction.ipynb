{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6008a1b6-263f-4cb1-ac5c-0963685ae42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "behaviour_df=pd.read_csv(\"cleaned_processed_customer_data.csv\")\n",
    "\n",
    "behaviour_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf97139-f71a-483d-a882-f04be8fa3828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Copy dataset ---\n",
    "df = behaviour_df.copy()\n",
    "\n",
    "\n",
    "# --- Step 2: Target encoding ---\n",
    "df['category_encoded'] = df['category'].astype('category').cat.codes\n",
    "\n",
    "# --- Step 3: ENHANCED Feature engineering for buying behavior prediction ---\n",
    "# Purchase behavior features\n",
    "df['avg_spent_per_day'] = df['purchase_amount'] / (df['purchase_frequency_days'] + 1)\n",
    "df['is_high_spender'] = (df['purchase_amount'] > df['purchase_amount'].quantile(0.75)).astype(int)\n",
    "df['price_per_frequency'] = df['purchase_amount'] / (df['purchase_frequency_days'] + 1)\n",
    "df['is_frequent_buyer'] = (df['purchase_frequency_days'] < df['purchase_frequency_days'].quantile(0.25)).astype(int)\n",
    "\n",
    "# Value-based segmentation\n",
    "df['customer_value'] = df['purchase_amount'] * (30 / (df['purchase_frequency_days'] + 1))\n",
    "df['high_value_customer'] = (df['customer_value'] > df['customer_value'].quantile(0.75)).astype(int)\n",
    "\n",
    "# Discount sensitivity\n",
    "df['discount_user'] = df['discount_applied'].map({'Yes': 1, 'No': 0})\n",
    "df['promo_user'] = df['promo_code_used'].map({'Yes': 1, 'No': 0})\n",
    "df['deal_seeker'] = ((df['discount_user'] == 1) | (df['promo_user'] == 1)).astype(int)\n",
    "\n",
    "# Loyalty indicators\n",
    "df['is_subscriber'] = df['subscription_status'].map({'Yes': 1, 'No': 0})\n",
    "df['loyalty_score'] = df['is_subscriber'] + df['is_frequent_buyer'] + (df['review_rating'] >= 4).astype(int)\n",
    "\n",
    "# Strategic interaction features for buying prediction\n",
    "df['gender_season'] = df['gender'] + '_' + df['season']\n",
    "df['age_group_frequency'] = df['age_group'] + '_' + df['frequency_of_purchases']\n",
    "\n",
    "# --- Step 4: Define X and y ---\n",
    "X = df.drop(columns=['category', 'category_encoded', 'customer_id', 'item_purchased'])\n",
    "y = df['category_encoded']\n",
    "\n",
    "# Check class balance BEFORE SMOTE\n",
    "print(\"=\"*60)\n",
    "print(\"CLASS DISTRIBUTION (BEFORE SMOTE)\")\n",
    "print(\"=\"*60)\n",
    "print(y.value_counts().sort_index())\n",
    "print(f\"\\nTotal samples: {len(y)}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "categorical_cols = [\n",
    "    'gender',           \n",
    "    'age_group',        \n",
    "    'size',             \n",
    "    'color',            \n",
    "    'season',           \n",
    "    'frequency_of_purchases',  \n",
    "    'gender_season',    \n",
    "    'age_group_frequency',  \n",
    "]\n",
    "\n",
    "# High-value numeric features for purchase prediction\n",
    "numeric_cols = [\n",
    "    'purchase_amount',        \n",
    "    'review_rating',          \n",
    "    'purchase_frequency_days',\n",
    "    'age',                    \n",
    "    'customer_value',         \n",
    "    'loyalty_score',         \n",
    "    'is_high_spender',        \n",
    "    'is_frequent_buyer',      \n",
    "    'high_value_customer',    \n",
    "    'deal_seeker',            \n",
    "    'is_subscriber',          \n",
    "    'discount_user',          \n",
    "    'promo_user',             \n",
    "]\n",
    "\n",
    "print(\"Selected Features:\")\n",
    "print(f\"Categorical: {len(categorical_cols)} features\")\n",
    "print(f\"Numeric: {len(numeric_cols)} features\")\n",
    "print(f\"Total: {len(categorical_cols) + len(numeric_cols)} features\\n\")\n",
    "\n",
    "# --- Step 5: Preprocessor ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "        ('num', StandardScaler(), numeric_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --- Step 6: Stratified train-test split (BEFORE SMOTE) ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAIN SET CLASS DISTRIBUTION (BEFORE SMOTE)\")\n",
    "print(\"=\"*60)\n",
    "print(pd.Series(y_train).value_counts().sort_index())\n",
    "print(f\"\\nTrain samples: {len(y_train)}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Step 7: XGBoost Model \n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=5,\n",
    "    min_child_weight=3,\n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    colsample_bylevel=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.5,\n",
    "    objective='multi:softprob',\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42,\n",
    "    tree_method='hist'\n",
    ")\n",
    "\n",
    "# --- Step 8: Build pipeline with SMOTE ---\n",
    "clf = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42, k_neighbors=5)),  # SMOTE after preprocessing\n",
    "    ('feature_selection', SelectKBest(mutual_info_classif, k='all')),\n",
    "    ('model', xgb_model)\n",
    "])\n",
    "\n",
    "# --- Step 9: Train model ---\n",
    "print(\"=\"*60)\n",
    "print(\"APPLYING SMOTE AND TRAINING MODEL...\")\n",
    "print(\"=\"*60)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Training complete!\\n\")\n",
    "\n",
    "# Show class distribution after SMOTE (indirectly, by checking what SMOTE would produce)\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAIN SET CLASS DISTRIBUTION (AFTER SMOTE)\")\n",
    "print(\"=\"*60)\n",
    "print(pd.Series(y_train_resampled).value_counts().sort_index())\n",
    "print(f\"\\nResampled train samples: {len(y_train_resampled)}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Step 10: Evaluate ---\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL EVALUATION (ON ORIGINAL TEST SET)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Weighted F1-Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"Macro F1-Score: {f1_score(y_test, y_pred, average='macro'):.4f}\")\n",
    "print(\"\\n\" + classification_report(y_test, y_pred, target_names=df['category'].unique()))\n",
    "\n",
    "# Cross-validation score\n",
    "print(\"=\"*60)\n",
    "print(\"CROSS-VALIDATION (WITH SMOTE)\")\n",
    "print(\"=\"*60)\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_weighted')\n",
    "print(f\"Cross-validation F1 Score: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "\n",
    "# Feature importance analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP 20 IMPORTANT FEATURES FOR PREDICTING NEXT PURCHASE\")\n",
    "print(\"=\"*60)\n",
    "feature_names = clf.named_steps['preprocessor'].get_feature_names_out()\n",
    "importances = clf.named_steps['model'].feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df.head(20))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e6eda-2172-410d-a030-580a09a840b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviour_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c4243d-0d47-4221-87ee-7e18fcc9b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save  trained pipeline as\n",
    "joblib.dump(clf, \"customer_behavior_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9a4a9f-4aec-49c9-8a43-b4b43cc0cd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5e373e-569c-4c7c-bc6a-5e8bc37b5eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3580725-4225-4a7f-afc9-d34366f70590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab155df-16e8-4467-bcc3-24390668c8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b663bee3-6e26-428b-acf2-6b6e9ba9b1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
